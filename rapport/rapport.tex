%%%% ijcai19.tex

\typeout{IJCAI-19 Instructions for Authors}

% These are the instructions for authors for IJCAI-19.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai19.sty is NOT the same than previous years'
\usepackage{ijcai19}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Étiquetage de la race de chien depuis une image à l'aide d'un réseau de neurone convolutif}

% Single author syntax
\iffalse
\author{
    Sarit Kraus
    \affiliations
    Department of Computer Science, Bar-Ilan University, Israel \emails
    pcchair@ijcai19.org
}
\fi

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% Check the ijcai19-multiauthor.tex file for detailed instructions
\author{
Antoine Gaulin\and
Othman Mounir\and
Arthur Pulvéric\And
Anis Redjdal\\
\affiliations
Polytechnique Montréal\\
}

\begin{document}

\maketitle

\begin{abstract}
% Décrire la thèse et le résultat en moins de 200 mots.
L'article a pour but de présenter un modèle de classification et d'étiquetage 
d'images de chiens en fonction de leur race.
\end{abstract}

\section{Introduction}

\subsection{Motivations}
Les réseaux de neurones convolutifs permettent de faire de la classification
d'image de façon rapide et performante. Ainsi, avec des images de chiens, il est
possible de calculer la probabilité qu'un canidé présent dans une image 
appartienne à une race plutôt qu’une autre. Pour aider la SPCA à se créer un
inventaire en ligne de tous ses chiens, et encourager le commerce en ligne, nous
voulons concevoir un réseau de neurones qui permet de faire de la classification
automatique à partir des images de chien. De cette façon, les clients souhaitant
faire l'acquisition d'une race spécifique auront plus de facilité à la retrouver
sur leur site internet.

Dans la pratique, un réseau de neurones convolutif classique présente des
difficultés pour la classification d’objets présentant de nombreuses
caractéristiques communes, ce qui est le cas pour les chiens de la base de 
données. La Fig. \ref{1} illustre bien ce problème : les chiens présentés ont
beaucoup de caractéristiques communes, mais n’appartiennent pas à la même race.
L’objectif ici est donc d’implémenter un modèle capable d’obtenir des
performances acceptables pour la prédiction de races de chien.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=2.8cm]{../dataset/test/n02110063-malamute/n02110063_11838.jpg}\hfill 
    \includegraphics[width=2.8cm]{../dataset/test/n02109961-Eskimo_dog/n02109961_623.jpg}\hfill 
    \includegraphics[width=2.8cm]{../dataset/test/n02110185-Siberian_husky/n02110185_7564.jpg} 
    \caption{De gauche à droite, un Malmute, un Eskimo et un Husky}
    \label{1} 
\end{figure} 

\subsection{Travaux antérieurs}
% Un petit résumé des travaux antérieurs qui existent dans la littérature.
L'article \textit{Using Convolutional Neural Networks to Classify Dog Breeds}
~\cite{fcdh_FinalReport} est un incontournable. Concrètement, les auteurs
proposent  deux architectures différentes capables de différencier les petites
variations entre les races. Le premier modèle est basé sur l'architecture de 
LeNet, dont chaque couche de convolution est un filtre avec 2 paramètres : le 
nombre de pixels qu’elles prennent en entrée et le nombre de canaux en sortie.
Le deuxième modèle reprend l'architecture de GoogLeNet, dont chaque couche de
convolution est une combinaison de filtres eux-mêmes composés de réseaux de
neurones.

Un autre papier intéressant est \textit{Dog Breed Identification}. 
~\cite{output} Il y est présenté un projet ayant pour but de prédire les races
des chiens à partir d’images. Ce projet utilise des techniques d’apprentissage
automatique et de vision par ordinateur. Un réseau de neurones convolutionnel
permet dans un premier temps d’identifier les points clés des visages des 
chiens. Ensuite, des descripteurs SIFT (Scale-Invariant Feature Transform) et 
des histogrammes de couleur utilisent ces points clés pour extraire des 
features. Enfin, un classificateur de type machine à vecteur de support (SVM,
Support-Vector Machine) prédit la race du chien avec une précision de 52\%. Il
est à noter que dans 90\% des cas, la race du chien à trouver est présente dans
les 10 prédictions les plus probables (sur 133 races au total dans la base de 
données). Ces performances sont supérieures à ce que peuvent faire la plupart
des humains.

Dans ce travail, nous nous inspirons d'un modèle proposé par le premier article.
En effet, la simplicité d’architecture et leurs bonnes performances sont
 totalement adaptées aux contraintes que nous rencontrons. Nous allons ajouter
un algorithme qui applique une étiquette sur l'image.

\section{Approche théorique}
% Un résumé de l'approche théorique formant la base du sujet du projet.

\subsection{Méthodologie}
Dans le contexte de la pandémie, nous devons limiter le projet à quelque chose 
de simple, qui permet toutefois de comprendre le fonctionnement d'un CNN 
moderne en profondeur. Ainsi, nous allons nous limiter à une seule architecture.

Premièrement, nous avons évalué s'il était possible d'ajouter des étiquettes à une
image dans ses métadonnées à l'aide du langage Python. Nous avons trouvé la
librairie IPTCInfo qui permet de faire cette tâche aisément.

Ensuite, nous avons cherché un dataset pour entrainer notre modèle. Les images
retenues proviennent du \textit{Stanford Dogs Dataset}. 
~\cite{KhoslaYaoJayadevaprakashFeiFei_FGVC2011} Le fait que les clichés soient
présents dans des répertoires nommés par la race permet facilement de retrouver
l'étiquette pour faire l'entrainement supervisé.

Pour concevoir le modèle, nous utilisons un GoogLeNet comme dans l'article 
\textit{Using Convolutional Neural Networks to Classify Dog Breeds} 
~\cite{output}. Ainsi, il nous a été utile de consulter l'article de Google,
\textit{Going deeper with convolutions} ~\cite{43022}, afin de bien comprendre
le fonctionnement du réseau.

\subsection{Le modèle}
Le modèle GoogLeNet créé par Google possède le mot LeNet dans son nom, car il
rend hommage à son prédécesseur LeNet qui est un des premiers modèles de
convolution à apporter de réelles prédictions de contenu d’images. Avant le
développement de GoogLeNet,  beaucoup d’autres modèles de convolution ont vu le
jour comme AlexNet, mais le modèle de Google reste celui qui a le pourcentage
d’erreur le plus bas et qui est donc le plus performant tel que présenté
sur la figure \ref{2} ~\cite{tsang_2018}.

\begin{figure}[htbp]
    \includegraphics[width=8.4cm]{./figures/Figure1.png} 
    \caption{Les modèles participants à l'ILSVRC 2014}
    \label{2} 
\end{figure} 

L'architecture de ce réseau GoogleNet est très différente des précédents réseaux
existants. Il contient des convolutions $1\times 1$ au milieu du réseau et le
regroupement moyen global est utilisé à la fin du réseau au lieu d’utiliser des
couches entièrement connectées. Ces deux techniques sont extraites d’un autre
article intitulé \textit{Network In Network}. ~\cite{lin2013network} Une autre
technique appelée module de création consiste à avoir différentes tailles ou
types de convolutions pour la même entrée. Ensuite, on empile toutes les 
sorties. Nous verrons plus en détail chacune de ces techniques ci-dessous.

\subsection{la convolution $1\times 1$}
Dans GoogLeNet, la convolution $1\times 1$ est utilisée comme module de
réduction de dimension pour réduire le calcul. En réduisant le goulot
d'étranglement du calcul, la profondeur et la largeur peuvent être augmentées.
Prenons un exemple simple pour illustrer cela. Supposons que nous devons
effectuer une convolution $5\times 5$ sans utiliser la convolution $1\times 1$
tel qu'illustré à la figure \ref{3} ~\cite{tsang_2018}.

\begin{figure}[htbp]
    \includegraphics[width=8.4cm]{./figures/Figure2.png} 
    \caption{Convolution de 112,9 millions opérations}
    \label{3} 
\end{figure} 

Voyons maintenant le nombre d’opérations effectuées si l’on ajoute une
convolution $1\times 1$ comme sur la figure \ref{4} ~\cite{tsang_2018}.

\begin{figure}[htbp]
    \includegraphics[width=8.4cm]{./figures/Figure3.png} 
    \caption{Convolution de 5,3 millions opérations}
    \label{4} 
\end{figure} 

Les deux sous-modèles de convolution ci-dessus donnent le même résultat et sont
donc équivalents. Cependant, lorsqu’on utilise la convolution $1\times 1$ en
plus on effectue beaucoup moins d’opérations ce qui revient donc à être moins
couteux. Ainsi, la convolution $1\times 1$ aide à réduire la taille du modèle,
ce qui peut également aider à réduire les problèmes de généralisation.

\subsection{Le module Inception}
Auparavant, comme avec AlexNet et VGGNet, la taille du filtre de convolution
était fixée pour chaque couche. Mais avec le module Inception, les filtres de
convolution $1\times 1$,  $3\times 3$ et  $5\times 5$ ainsi que la couche
maxPooling sont toutes appliquées à la sortie de la couche de neurones
précédente et chaque résultat de chacune de ces couches est envoyé vers une
couche de concaténation qui regroupe toutes ces sorties en un seul résultat.
L’architecture de ce module est de la forme représentée à la figure \ref{5}

%\begin{figure}[htbp]
%   \centering
%    \includegraphics[width=2.8cm]{../dataset/test/n02110185-Siberian_husky/n02110185_7564.jpg} 
%    \caption{De gauche à droite, un Malmute, un Eskimo et un Husky}
%    \label{5}
% \end{figure} 

Finalement, si on décide de regrouper et d’utiliser la convolution $1\times 1$
dans notre module Inception afin de réduire la dimension des couches $3\times 3$
et  $5\times 5$ pour qu’elles soient moins couteuses. On garde donc la variété
de résultats qu’offre l’assemblage de couches de convolution de différentes
tailles tout en prenant soin de réduire les dimensions pour éviter une surcharge
des opérations et par la même occasion les problèmes de généralisation comme
dans la figure \ref{6}.

%\begin{figure}[htbp]
%   \centering
%    \includegraphics[width=2.8cm]{../dataset/test/n02110185-Siberian_husky/n02110185_7564.jpg} 
%    \caption{De gauche à droite, un Malmute, un Eskimo et un Husky}
%    \label{6}
% \end{figure}

\subsection{Le regroupement moyen global}
Dans la plupart des CNN classiques et déjà réalisées, on utilise une couche
Fully Connected (FC) à la fin du réseau (à la sortie de la dernière couche de
convolution / pooling) en reliant toutes les entrées à toutes les sorties qui
sont égales au nombre de classes que l’on veut classifier à l’aide notre modèle
(chez nous 120 classes = 120 races de chiens différentes). Néanmoins, GoogLeNet
 n’utilise pas de couche FC à la fin pour la classification, mais bien une
couche que l’on va appeler Regroupement moyen global (GAP) en français qui
consiste à calculer pour chaque entrée une moyenne de probabilité qu’il va
envoyer directement à la sortie. Il n’y aura donc aucune matrice de poids W à
apprendre comme pour un réseau FC. Le concept du GAP est représenté à la figure
\ref{7}. ~\cite{tsang_2018}

\begin{figure}[htbp]
    \includegraphics[width=8.4cm]{./figures/Figure4.png} 
    \caption{Comparaison de FC et GAP}
    \label{7} 
\end{figure} 

On voit donc que le réseau FC utilise toutes les entrées pour déterminer une
sortie alors que le GPA utilise une entrée par sortie par rapport à un calcul 
des entrées moyennes. Le réseau GPA est donc moins couteux, mais en plus de cela
une étude des auteurs a confirmé qu'un passage de la couche FC à la couche GPA
améliore la précision du GoogLeNet de 0,6\% ce qui est remarquable. 

\subsection{Entraînement}
TODO

\section{Discussion}

Discussion de nos expériences. Incluant des figures, des tableaux de nos résultats.

Le code source est disponible à cette adresse : \url{https://github.com/Anteige/INF8225}.

\subsection{Exemples de tableau}

\begin{table}[htbp]
\centering
\begin{tabular}{lrr}  
\toprule
Scenario  & $\delta$ (s) & Runtime (ms) \\
\midrule
Paris       & 0.1  & 13.65      \\
            & 0.2  & 0.01       \\
New York    & 0.1  & 92.50      \\
Singapore   & 0.1  & 33.33      \\
            & 0.2  & 23.01      \\
\bottomrule
\end{tabular}
\caption{Booktabs table}
\label{tab:booktabs}
\end{table}

\subsection{Exemple d'algorithme}

\begin{algorithm}[htbp]
\caption{Example algorithm}
\label{alg:algorithm}
\textbf{Input}: Your algorithm's input\\
\textbf{Parameter}: Optional list of parameters\\
\textbf{Output}: Your algorithm's output
\begin{algorithmic}[1] %[1] enables line numbers
\STATE Let $t=0$.
\WHILE{condition}
\STATE Do some action.
\IF {conditional}
\STATE Perform task A.
\ELSE
\STATE Perform task B.
\ENDIF
\ENDWHILE
\STATE \textbf{return} solution
\end{algorithmic}
\end{algorithm}

\section{Analyse}

Une analyze critique de l'approche que vous avez utilisée pour apprendre le sujet que vous avez sélectionné.


%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{rapport}

\end{document}

