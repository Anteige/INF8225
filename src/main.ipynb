{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x25af00bc488>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import import_dataset as load\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut chargement image\n",
      "debut chargement image\n",
      "(318, 1, 224, 224)\n",
      "(318,)\n"
     ]
    }
   ],
   "source": [
    "#Importation du data\n",
    "train_path = \"../dataset/train\" \n",
    "test_path = \"../dataset/test\" \n",
    "\n",
    "train_dataset_X, train_dataset_Y = load.loadDataset4D(train_path)\n",
    "test_dataset_X, test_dataset_Y = load.loadDataset4D(test_path)\n",
    "\n",
    "print(train_dataset_X.shape)\n",
    "print(train_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on Y labels\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_dataset_Y = encoder.fit_transform(train_dataset_Y)\n",
    "test_dataset_Y = encoder.fit_transform(test_dataset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR 2D ONLY \n",
    "\n",
    "# train_df_X = pd.DataFrame(train_dataset_X)\n",
    "# train_df_Y = pd.DataFrame(train_dataset_Y)\n",
    "# test_df_X = pd.DataFrame(test_dataset_X)\n",
    "# test_df_Y = pd.DataFrame(test_dataset_Y)\n",
    "\n",
    "# train_df_Y.head()\n",
    "\n",
    "# FOR 4D ONLY \n",
    "# train_dataset_X_conv = np.ones([12000, 1, 224, 224])\n",
    "\n",
    "\n",
    "# print(train_dataset_X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([318, 1, 224, 224])\n",
      "torch.Size([318])\n",
      "torch.Size([318, 1, 224, 224])\n",
      "torch.Size([318])\n"
     ]
    }
   ],
   "source": [
    "#Create custom dataLoader\n",
    "\n",
    "class DogsDataset(Dataset):\n",
    "    \"\"\" Dogs dataset.\"\"\"\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, Y):\n",
    "        self.len = Y.shape[0]\n",
    "        self.x_data = torch.from_numpy(X).float()\n",
    "        self.y_data = torch.from_numpy(Y).float()\n",
    "        print(self.x_data.shape)\n",
    "        print(self.y_data.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "dataset_train = DogsDataset(train_dataset_X, train_dataset_Y)\n",
    "dataset_test = DogsDataset(test_dataset_X, test_dataset_Y)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset_train,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loaders: \n",
    "\n",
    "#trainloaderX = DataLoader(train_df_X, batch_size=4, shuffle=True, num_workers=2)\n",
    "#testloaderX = DataLoader(test_df_X, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réseau à 4 couches\n",
    "class ModelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # On défini nos couches:\n",
    "    \n",
    "        #Premiere couche de convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.fonction1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fonction2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.output = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.reshape(-1, 12*4*4) # surement important adapter à la size de l'image \n",
    "        x = self.fonction1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fonction2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        # output\n",
    "        x = self.output(x)\n",
    "        #x = nn.Softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance du model \n",
    "\n",
    "model = ModelCNN()\n",
    "\n",
    "# Définir la fonction de loss : \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #Essayer avec Adam aussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 224, 224])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Softmax' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d306c096b69e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 576\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Softmax' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#Training the network \n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "#         print(\"on est passés dans la boucle :\")\n",
    "#         print(data)\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        \n",
    "        print(outputs.shape)\n",
    "        print(labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier les keyword des images de test pour les retrouver\n",
    "\n",
    "from iptcinfo3 import IPTCInfo\n",
    "info = IPTCInfo('oiseau.jpg')\n",
    "info['keywords'] = [\"key1\",  \"key2\"]\n",
    "info.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
