{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import import_dataset as load\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut chargement image\n",
      "debut chargement image\n",
      "(318, 3, 224, 224)\n",
      "(318,)\n"
     ]
    }
   ],
   "source": [
    "#Importation du data\n",
    "train_path = \"../dataset/train\" \n",
    "test_path = \"../dataset/test\" \n",
    "\n",
    "train_dataset_X, train_dataset_Y = load.loadDataset(train_path)\n",
    "test_dataset_X, test_dataset_Y = load.loadDataset(test_path)\n",
    "\n",
    "print(train_dataset_X.shape)\n",
    "print(train_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 3, 224, 224)\n",
      "(318,)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset_X.shape)\n",
    "print(test_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Y labels\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_dataset_Y = encoder.fit_transform(train_dataset_Y)\n",
    "test_dataset_Y = encoder.fit_transform(test_dataset_Y)\n",
    "\n",
    "print(np.unique(test_dataset_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([318, 3, 224, 224])\n",
      "torch.Size([318])\n",
      "torch.Size([318, 3, 224, 224])\n",
      "torch.Size([318])\n"
     ]
    }
   ],
   "source": [
    "#Create custom dataLoader\n",
    "\n",
    "class DogsDataset(Dataset):\n",
    "    \"\"\" Dogs dataset.\"\"\"\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, Y):\n",
    "        self.len = Y.shape[0]\n",
    "        self.x_data = torch.from_numpy(X).float()\n",
    "        self.y_data = torch.from_numpy(Y).float()\n",
    "        print(self.x_data.shape)\n",
    "        print(self.y_data.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "dataset_train = DogsDataset(train_dataset_X, train_dataset_Y)\n",
    "dataset_test = DogsDataset(test_dataset_X, test_dataset_Y)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset_train,\n",
    "                          batch_size=100,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(dataset=dataset_test,\n",
    "                          shuffle=True,\n",
    "                          batch_size=1,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            Conv2d(3, 10, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(10),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(10, 20, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(20),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(62720, 120) # A  changer soon \n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(inputs)\n",
    "\n",
    "        print(\"output_train\")\n",
    "        print(output_train)\n",
    "        print(\"labels\")\n",
    "        print(labels)\n",
    "        loss_train = criterion(output_train, labels.long())\n",
    "        train_losses.append(loss_train)\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss_train.item()\n",
    "        # i1 = i1 + 100\n",
    "        # i2 = i2 + 100\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_train)\n",
    "    return tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and predictions : \n",
    "\n",
    "test_dataset_X  = torch.from_numpy(test_dataset_X).float()\n",
    "test_dataset_Y = torch.from_numpy(test_dataset_Y).float()\n",
    "\n",
    "print(test_dataset_X.shape)\n",
    "print(test_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./model.pth'))\n",
    "# generating predictions for test set\n",
    "# output = model(test_dataset_X)\n",
    "\n",
    "# softmax = torch.nn.Softmax(output)\n",
    "# prob = list(softmax.numpy())\n",
    "# predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "# # accuracy on training set\n",
    "# accuracy_score(train_y, predictions)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        outputs = model(test_dataset_X)\n",
    "        # predicted = torch.nn.Softmax(outputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += test_dataset_Y.size(0)\n",
    "        correct += (predicted == test_dataset_Y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
