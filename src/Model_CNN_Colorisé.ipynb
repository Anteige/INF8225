{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import import_dataset as load\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut chargement image\n",
      "debut chargement image\n",
      "(318, 3, 224, 224)\n",
      "(318,)\n"
     ]
    }
   ],
   "source": [
    "#Importation du data\n",
    "train_path = \"../dataset/train\" \n",
    "test_path = \"../dataset/test\" \n",
    "\n",
    "train_dataset_X, train_dataset_Y = load.loadDataset(train_path)\n",
    "test_dataset_X, test_dataset_Y = load.loadDataset(test_path)\n",
    "\n",
    "print(train_dataset_X.shape)\n",
    "print(train_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 3, 224, 224)\n",
      "(318,)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset_X.shape)\n",
    "print(test_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Y labels\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_dataset_Y = encoder.fit_transform(train_dataset_Y)\n",
    "test_dataset_Y = encoder.fit_transform(test_dataset_Y)\n",
    "\n",
    "print(np.unique(test_dataset_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([318, 3, 224, 224])\n",
      "torch.Size([318])\n"
     ]
    }
   ],
   "source": [
    "train_dataset_X  = torch.from_numpy(train_dataset_X).float()\n",
    "train_dataset_Y = torch.from_numpy(train_dataset_Y).float()\n",
    "\n",
    "print(train_dataset_X.shape)\n",
    "print(train_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 10, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(10),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(10, 20, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(20),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(12544, 12000) # A  changer soon \n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=12000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# model.to(device)\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "# /\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_dataset_X, train_dataset_Y):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    X_shuffle, y_shuffle = shuffle(train_dataset_X, train_dataset_Y, random_state=0)\n",
    "    minibatch = 100\n",
    "    for i in range (0, X_shuffle.shape[0], minibatch):\n",
    "        # train_X, train_Y = Variable(train_dataset_X[i*stride:(i+1)*stride].cuda()), Variable(train_dataset_Y[i*stride:(i+1)*stride].cuda())\n",
    "        train_X, train_Y = Variable(train_dataset_X[i:i + minibatch]), Variable(train_dataset_Y[i:i + minibatch])\n",
    "\n",
    "    # converting the data into GPU format\n",
    "#     if torch.cuda.is_available():\n",
    "#         train_X = train_X.cuda()\n",
    "#         train_Y = train_Y.cuda()\n",
    "        \n",
    "    # clearing the Gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "        output_train = model(train_X)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "        loss_train = criterion(output_train, train_Y.long())\n",
    "        train_losses.append(loss_train)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss = loss_train.item()\n",
    "        # i1 = i1 + 100\n",
    "        # i2 = i2 + 100\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_train)\n",
    "    return tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[143., 141., 142.,  ..., 152., 157., 156.],\n",
      "          [151., 156., 155.,  ..., 173., 175., 174.],\n",
      "          [174., 176., 174.,  ..., 181., 181., 191.],\n",
      "          ...,\n",
      "          [202., 200., 217.,  ..., 157., 172., 175.],\n",
      "          [144., 146., 141.,  ...,  91., 113., 100.],\n",
      "          [ 94., 115., 102.,  ..., 201., 199., 213.]],\n",
      "\n",
      "         [[202., 200., 216.,  ..., 124., 145., 148.],\n",
      "          [145., 147., 142.,  ...,  90., 112.,  99.],\n",
      "          [ 93., 114.,  99.,  ..., 201., 199., 212.],\n",
      "          ...,\n",
      "          [101., 124., 104.,  ..., 178., 182., 148.],\n",
      "          [136., 140., 119.,  ..., 188., 183., 145.],\n",
      "          [146., 128., 104.,  ...,  98., 127., 108.]],\n",
      "\n",
      "         [[101., 124., 104.,  ..., 166., 173., 139.],\n",
      "          [127., 131., 113.,  ..., 186., 181., 143.],\n",
      "          [147., 127., 103.,  ...,  96., 125., 106.],\n",
      "          ...,\n",
      "          [148., 109., 104.,  ..., 110., 152., 144.],\n",
      "          [108., 152., 144.,  ..., 161., 126., 166.],\n",
      "          [163., 128., 166.,  ..., 176., 178., 139.]]],\n",
      "\n",
      "\n",
      "        [[[ 93.,  71.,  57.,  ..., 136., 181., 159.],\n",
      "          [136., 181., 159.,  ..., 155., 127., 185.],\n",
      "          [155., 127., 185.,  ...,  68.,  34.,   7.],\n",
      "          ...,\n",
      "          [106.,  76., 152.,  ..., 148.,  98.,  61.],\n",
      "          [135.,  86.,  53.,  ...,  66., 142.,  93.],\n",
      "          [ 63., 139.,  90.,  ..., 118.,  88., 165.]],\n",
      "\n",
      "         [[118.,  92., 162.,  ..., 151., 102.,  62.],\n",
      "          [136.,  88.,  52.,  ...,  68., 146.,  96.],\n",
      "          [ 63., 142.,  91.,  ..., 108.,  82., 153.],\n",
      "          ...,\n",
      "          [117., 181., 141.,  ..., 110.,  92., 147.],\n",
      "          [110.,  94., 147.,  ..., 190., 145., 114.],\n",
      "          [206., 163., 131.,  ..., 117., 187., 148.]],\n",
      "\n",
      "         [[119., 182., 142.,  ..., 109.,  91., 147.],\n",
      "          [110.,  94., 149.,  ..., 187., 142., 111.],\n",
      "          [200., 157., 125.,  ..., 130., 198., 159.],\n",
      "          ...,\n",
      "          [160., 114.,  81.,  ...,  94., 162., 117.],\n",
      "          [ 94., 160., 115.,  ..., 136., 116., 174.],\n",
      "          [128., 105., 168.,  ..., 151., 106.,  75.]]],\n",
      "\n",
      "\n",
      "        [[[ 73.,  50.,  44.,  ...,  54.,  95.,  65.],\n",
      "          [ 55.,  96.,  66.,  ...,  57.,  45.,  95.],\n",
      "          [ 61.,  49.,  90.,  ...,  69.,  31.,  22.],\n",
      "          ...,\n",
      "          [ 87.,  57., 117.,  ..., 111.,  78.,  71.],\n",
      "          [106.,  78.,  67.,  ...,  84., 127.,  99.],\n",
      "          [ 87., 139., 111.,  ...,  88.,  58., 125.]],\n",
      "\n",
      "         [[ 89.,  57., 135.,  ..., 100.,  67.,  60.],\n",
      "          [ 96.,  68.,  57.,  ...,  77., 123.,  95.],\n",
      "          [ 83., 138., 110.,  ...,  88.,  56., 119.],\n",
      "          ...,\n",
      "          [ 69., 137., 103.,  ..., 134.,  83., 177.],\n",
      "          [131.,  81., 169.,  ..., 104.,  71.,  54.],\n",
      "          [108.,  89.,  83.,  ...,  67., 140., 104.]],\n",
      "\n",
      "         [[ 68., 141., 105.,  ..., 122.,  72., 168.],\n",
      "          [122.,  72., 166.,  ...,  95.,  62.,  45.],\n",
      "          [116.,  99.,  92.,  ...,  72., 145., 109.],\n",
      "          ...,\n",
      "          [144., 122., 109.,  ..., 120., 171., 142.],\n",
      "          [128., 179., 150.,  ..., 142., 124., 178.],\n",
      "          [149., 131., 181.,  ..., 129.,  97.,  82.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 68.,  58.,  57.,  ...,  68.,  90.,  69.],\n",
      "          [ 64.,  89.,  70.,  ..., 138., 133., 151.],\n",
      "          [132., 125., 148.,  ..., 109.,  95.,  92.],\n",
      "          ...,\n",
      "          [ 66.,  42.,  95.,  ..., 125., 110., 107.],\n",
      "          [104.,  85.,  87.,  ...,  97., 140., 106.],\n",
      "          [ 81., 144., 110.,  ...,  90.,  64., 127.]],\n",
      "\n",
      "         [[ 91.,  67., 114.,  ..., 118., 102., 102.],\n",
      "          [ 84.,  67.,  73.,  ..., 106., 138., 106.],\n",
      "          [ 83., 142., 108.,  ..., 119.,  93., 158.],\n",
      "          ...,\n",
      "          [145., 202., 171.,  ..., 202., 177., 224.],\n",
      "          [187., 160., 199.,  ...,  96.,  82.,  73.],\n",
      "          [ 75.,  54.,  51.,  ..., 132., 201., 175.]],\n",
      "\n",
      "         [[152., 224., 193.,  ..., 195., 173., 221.],\n",
      "          [185., 159., 207.,  ..., 118., 101.,  93.],\n",
      "          [ 79.,  58.,  53.,  ..., 122., 202., 174.],\n",
      "          ...,\n",
      "          [ 95.,  69.,  56.,  ..., 112., 151., 113.],\n",
      "          [ 94., 132.,  93.,  ..., 224., 198., 232.],\n",
      "          [208., 182., 210.,  ..., 179., 170., 141.]]],\n",
      "\n",
      "\n",
      "        [[[ 42.,  47.,  17.,  ...,   4.,  73.,  40.],\n",
      "          [  0.,  64.,  31.,  ..., 107.,   6., 100.],\n",
      "          [109.,   2., 118.,  ...,  32.,  47.,   0.],\n",
      "          ...,\n",
      "          [ 53.,   6., 103.,  ...,  17.,  17.,   9.],\n",
      "          [ 96., 107.,  31.,  ...,  37., 183., 113.],\n",
      "          [ 43., 179., 111.,  ...,  55.,   5., 107.]],\n",
      "\n",
      "         [[ 51.,   4., 102.,  ...,  14.,  14.,   6.],\n",
      "          [ 97., 108.,  30.,  ...,  37., 182., 112.],\n",
      "          [ 42., 178., 110.,  ...,  53.,   4., 103.],\n",
      "          ...,\n",
      "          [ 12.,  96.,  57.,  ...,  44.,  27.,  38.],\n",
      "          [ 16.,   2.,  38.,  ...,  94.,  94.,  30.],\n",
      "          [134., 138.,  44.,  ...,  10.,  90.,  50.]],\n",
      "\n",
      "         [[ 14.,  97.,  58.,  ...,  40.,  23.,  39.],\n",
      "          [ 17.,   3.,  37.,  ..., 100., 100.,  36.],\n",
      "          [132., 135.,  44.,  ...,  12.,  91.,  51.],\n",
      "          ...,\n",
      "          [134., 144.,  47.,  ...,   5., 144., 152.],\n",
      "          [ 43., 127., 136.,  ..., 148.,  26., 105.],\n",
      "          [123.,   3.,  89.,  ..., 131., 141.,  28.]]],\n",
      "\n",
      "\n",
      "        [[[141., 113.,  99.,  ...,  90., 134., 108.],\n",
      "          [ 91., 134., 108.,  ..., 114., 110., 144.],\n",
      "          [115., 111., 144.,  ..., 121.,  95.,  78.],\n",
      "          ...,\n",
      "          [168., 142., 182.,  ..., 143., 121., 107.],\n",
      "          [132., 112., 101.,  ...,  71., 153., 127.],\n",
      "          [100., 175., 146.,  ..., 159., 131., 187.]],\n",
      "\n",
      "         [[157., 133., 169.,  ..., 136., 113.,  97.],\n",
      "          [136., 116., 105.,  ...,  79., 158., 132.],\n",
      "          [107., 177., 146.,  ..., 159., 134., 177.],\n",
      "          ...,\n",
      "          [ 74., 130., 102.,  ...,  35.,  20.,  70.],\n",
      "          [ 41.,  23.,  70.,  ..., 143., 116., 107.],\n",
      "          [132., 109., 101.,  ...,  60., 120.,  92.]],\n",
      "\n",
      "         [[ 80., 137., 109.,  ...,  37.,  21.,  66.],\n",
      "          [ 37.,  19.,  66.,  ..., 142., 115., 106.],\n",
      "          [129., 106.,  98.,  ...,  72., 131., 103.],\n",
      "          ...,\n",
      "          [134., 106.,  85.,  ..., 101., 138., 112.],\n",
      "          [ 99., 143., 117.,  ..., 113., 102., 142.],\n",
      "          [115., 104., 145.,  ..., 127., 100.,  91.]]]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "take(): argument 'index' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4ca2caf81e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c97585a3fa31>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, train_dataset_X, train_dataset_Y)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# getting the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mminibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_shuffle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \"\"\"\n\u001b[0;32m    448\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[0mresampled_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[0mresampled_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    217\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: take(): argument 'index' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 25\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    print(train_dataset_X)\n",
    "    test = train(epoch, train_dataset_X, train_dataset_Y)\n",
    "    print(test)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and predictions : \n",
    "\n",
    "test_dataset_X = test_dataset_X.reshape(8580, 1, 224, 224)\n",
    "test_dataset_X  = torch.from_numpy(test_dataset_X).float()\n",
    "test_dataset_Y = torch.from_numpy(test_dataset_Y).float()\n",
    "\n",
    "print(test_dataset_X.shape)\n",
    "print(test_dataset_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./model.pth'))\n",
    "# generating predictions for test set\n",
    "# output = model(test_dataset_X)\n",
    "\n",
    "# softmax = torch.nn.Softmax(output)\n",
    "# prob = list(softmax.numpy())\n",
    "# predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "# # accuracy on training set\n",
    "# accuracy_score(train_y, predictions)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        outputs = model(test_dataset_X)\n",
    "        # predicted = torch.nn.Softmax(outputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += test_dataset_Y.size(0)\n",
    "        correct += (predicted == test_dataset_Y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
